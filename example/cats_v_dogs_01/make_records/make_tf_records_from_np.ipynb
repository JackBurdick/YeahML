{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 6, 5, 'final', 0)\n",
      "TensorFlow: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this is a custom cell that contains the common imports I personally \n",
    "# use these may/may not be necessary for the following examples\n",
    "\n",
    "# DL framework\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# common packages\n",
    "import numpy as np\n",
    "import os # handling file i/o\n",
    "import sys\n",
    "import math\n",
    "import time # timing epochs\n",
    "\n",
    "# for ordered dict when building layer components\n",
    "import collections\n",
    "\n",
    "# plotting pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors # making colors consistent\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # colorbar helper\n",
    "\n",
    "# read image\n",
    "### from imageio import imread\n",
    "# + data augmentation\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "# used for manually saving best params\n",
    "import pickle\n",
    "\n",
    "# for shuffling data batches\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# const\n",
    "SEED = 42\n",
    "\n",
    "# Helper to make the output consistent\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "    \n",
    "# set tf log level to supress messages, unless an error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Important Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/record_holder/150/ created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# `/record_holder` will (hopefully) contain our tf_records file# `/rec \n",
    "# by the end of this notebook\n",
    "FINAL_DIR = \"./data/record_holder/150/\"\n",
    "maybe_create_dir(FINAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.npy\n",
      "X_train.npy\n",
      "X_val.npy\n",
      "y_test.npy\n",
      "y_train.npy\n",
      "y_val.npy\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"./data/numpy/150/\"\n",
    "\n",
    "for _, _, files in os.walk(ROOT_DIR):\n",
    "    files = sorted(files)\n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "        \n",
    "X_test = np.load(os.path.join(ROOT_DIR, files[0]))\n",
    "X_train = np.load(os.path.join(ROOT_DIR, files[1]))\n",
    "X_val = np.load(os.path.join(ROOT_DIR, files[2]))\n",
    "y_test = np.load(os.path.join(ROOT_DIR, files[3]))\n",
    "y_train = np.load(os.path.join(ROOT_DIR, files[4]))\n",
    "y_val = np.load(os.path.join(ROOT_DIR, files[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tfrecords(features, lables, setType):\n",
    "    tfrecords_file_name = str(setType) + '.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(os.path.join(FINAL_DIR, tfrecords_file_name))\n",
    "    \n",
    "    labelName = str(setType) + '/label'\n",
    "    featureName = str(setType) + '/image'\n",
    "    \n",
    "    # TODO: assert same length\n",
    "    for i in range(len(features)):\n",
    "        label = lables[i]\n",
    "        img = features[i]\n",
    "    \n",
    "        # create features\n",
    "        feature = {labelName: _int64_feature(label),\n",
    "                   featureName: _bytes_feature(tf.compat.as_bytes(img.tostring()))}\n",
    "        \n",
    "        # create example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "        if i % 250 == 0:\n",
    "            print(\"{} {} written\".format(i, setType))\n",
    "        \n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 test written\n",
      "250 test written\n",
      "500 test written\n",
      "750 test written\n",
      "1000 test written\n",
      "1250 test written\n",
      "1500 test written\n",
      "1750 test written\n",
      "2000 test written\n",
      "2250 test written\n",
      "2500 test written\n",
      "2750 test written\n",
      "3000 test written\n",
      "3250 test written\n",
      "3500 test written\n",
      "3750 test written\n",
      "4000 test written\n",
      "4250 test written\n",
      "4500 test written\n",
      "4750 test written\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numpy_to_tfrecords(X_test, y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val written\n",
      "250 val written\n",
      "500 val written\n",
      "750 val written\n",
      "1000 val written\n",
      "1250 val written\n",
      "1500 val written\n",
      "1750 val written\n",
      "2000 val written\n",
      "2250 val written\n",
      "2500 val written\n",
      "2750 val written\n",
      "3000 val written\n",
      "3250 val written\n",
      "3500 val written\n",
      "3750 val written\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numpy_to_tfrecords(X_val, y_val, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train written\n",
      "250 train written\n",
      "500 train written\n",
      "750 train written\n",
      "1000 train written\n",
      "1250 train written\n",
      "1500 train written\n",
      "1750 train written\n",
      "2000 train written\n",
      "2250 train written\n",
      "2500 train written\n",
      "2750 train written\n",
      "3000 train written\n",
      "3250 train written\n",
      "3500 train written\n",
      "3750 train written\n",
      "4000 train written\n",
      "4250 train written\n",
      "4500 train written\n",
      "4750 train written\n",
      "5000 train written\n",
      "5250 train written\n",
      "5500 train written\n",
      "5750 train written\n",
      "6000 train written\n",
      "6250 train written\n",
      "6500 train written\n",
      "6750 train written\n",
      "7000 train written\n",
      "7250 train written\n",
      "7500 train written\n",
      "7750 train written\n",
      "8000 train written\n",
      "8250 train written\n",
      "8500 train written\n",
      "8750 train written\n",
      "9000 train written\n",
      "9250 train written\n",
      "9500 train written\n",
      "9750 train written\n",
      "10000 train written\n",
      "10250 train written\n",
      "10500 train written\n",
      "10750 train written\n",
      "11000 train written\n",
      "11250 train written\n",
      "11500 train written\n",
      "11750 train written\n",
      "12000 train written\n",
      "12250 train written\n",
      "12500 train written\n",
      "12750 train written\n",
      "13000 train written\n",
      "13250 train written\n",
      "13500 train written\n",
      "13750 train written\n",
      "14000 train written\n",
      "14250 train written\n",
      "14500 train written\n",
      "14750 train written\n",
      "15000 train written\n",
      "15250 train written\n",
      "15500 train written\n",
      "15750 train written\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numpy_to_tfrecords(X_train, y_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_edge",
   "language": "python",
   "name": "dl_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
