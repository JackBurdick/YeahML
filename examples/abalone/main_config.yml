meta:
  name: 'abalone'
  experiment_dir: 'trial_00'
  # TODO: information on when to save params, currently only best params saved
logging:
  console:
    level: 'info'
    format_str: null
  file:
    level: 'ERROR'
    format_str: null
  graph_spec: True

performance:
  loss_fn: 
    type: 'MSE'
  type: ["MeanSquaredError", "MeanAbsoluteError"]
  options: [null, 
            null]

# TODO: this section needs to be redone
data:
  in:
    dim: [2,1]
    dtype: 'float64'
  label:
    dim: [1]
    dtype: 'int32'

hyper_parameters:
  optimizer: 
    type: 'adam'
    learning_rate: 0.0001
  epochs: 30
  dataset:
    # TODO: I would like to make this logic more abstract
    # I think the only options that should be applied here are "batch" and "shuffle"
    batch: 16
    shuffle: 128 # this should be grouped with batchsize
model:
  path: './model_config.yml'

