meta:
  name: "model_a"
  name_override: True
  activation:
    type: 'elu'

layers:
  dense_1:
    type: 'dense'
    options:
      units: 16
    in_name: 'data_features'
  dense_2:
    type: 'dense'
    options:
      units: 8
      activation:
        type: 'elu'
  dense_out:
    type: 'dense'
    options:
      units: 1
      activation:
        type: 'linear'

# TODO: need to support this case
  # dense_3_a:
  #   type: 'dense'
  #   options:
  #     units: 2
  #     activation:
  #       type: 'elu'
  # dense_3_b:
  #   type: 'dense'
  #   options:
  #     units: 2
  #     activation:
  #       type: 'elu'
  # dense_4:
  #   type: 'concatenate'
  #   options:
  #     axis: -1
  #   in_name: ['dense_3_a', 'dense_3_b']
  # dense_out:
  #   type: 'dense'
  #   options:
  #     units: 1
  #     activation:
  #       type: 'linear'


    # "layers": {
    #     "dense_1": {
    #         "type": "dense",
    #         "options": {
    #             "units": "16",
    #             "kernel_initializer": {"type": "glorotnormal"},
    #             "bias_regularizer": {"type": "l2", "options": {"l": 0.3}},
    #             "activation": {"type": "elu"},
    #         },
    #         "in_name": "jack",
    #     },
    #     "bn_1": {
    #         "type": "batchnormalization",
    #         "options": None,
    #         "in_name": "dense_1",
    #     },
    #     "dense_2": {
    #         "type": "dense",
    #         "options": {
    #             "units": "16",
    #             "kernel_initializer": {"type": "glorotnormal"},
    #             "bias_regularizer": {"type": "l2", "options": {"l": 0.3}},
