{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 6, 5, 'final', 0)\n",
      "TensorFlow: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this is a custom cell that contains the common imports I personally \n",
    "# use these may/may not be necessary for the following examples\n",
    "\n",
    "# DL framework\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# common packages\n",
    "import numpy as np\n",
    "import os # handling file i/o\n",
    "import sys\n",
    "import math\n",
    "import time # timing epochs\n",
    "\n",
    "# for ordered dict when building layer components\n",
    "import collections\n",
    "\n",
    "# plotting pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors # making colors consistent\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # colorbar helper\n",
    "\n",
    "# read image\n",
    "### from imageio import imread\n",
    "# + data augmentation\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "# used for manually saving best params\n",
    "import pickle\n",
    "\n",
    "# for shuffling data batches\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# const\n",
    "SEED = 42\n",
    "\n",
    "# Helper to make the output consistent\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "    \n",
    "# set tf log level to supress messages, unless an error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Important Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/224_224/ created\n"
     ]
    }
   ],
   "source": [
    "# `/record_holder` will (hopefully) contain our tf_records file# `/rec \n",
    "# by the end of this notebook\n",
    "FINAL_DIR = \"../data/224_224/\"\n",
    "maybe_create_dir(FINAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.npy\n",
      "test_masks.npy\n",
      "train.npy\n",
      "train_masks.npy\n",
      "validation.npy\n",
      "validation_masks.npy\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"./numpy_final/224_224/\"\n",
    "\n",
    "for _, _, files in os.walk(ROOT_DIR):\n",
    "    files = sorted(files)\n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "\n",
    "X_test = np.load(os.path.join(ROOT_DIR, files[0]))\n",
    "y_test = np.load(os.path.join(ROOT_DIR, files[1]))\n",
    "\n",
    "X_train = np.load(os.path.join(ROOT_DIR, files[2]))\n",
    "y_train = np.load(os.path.join(ROOT_DIR, files[3]))\n",
    "\n",
    "X_val = np.load(os.path.join(ROOT_DIR, files[4]))\n",
    "y_val = np.load(os.path.join(ROOT_DIR, files[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tfrecords(features, lables, setType):\n",
    "    assert len(features) == len(lables), \"features & labels are not equal in len\"\n",
    "    tfrecords_file_name = str(setType) + '.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(os.path.join(FINAL_DIR, tfrecords_file_name))\n",
    "    \n",
    "    # TODO: assert same length\n",
    "    for i in range(len(features)):\n",
    "        img = features[i]\n",
    "        label = lables[i]\n",
    "    \n",
    "        # create features\n",
    "        feature = {'/label': _bytes_feature(tf.compat.as_bytes(img.tostring())),\n",
    "                   '/image': _bytes_feature(tf.compat.as_bytes(label.tostring()))}\n",
    "        \n",
    "        # create example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "        if i % 250 == 0:\n",
    "            print(\"{} {} written\".format(i, setType))\n",
    "        \n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 validation written\n",
      "250 validation written\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numpy_to_tfrecords(X_val, y_val, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train written\n",
      "250 train written\n",
      "500 train written\n",
      "750 train written\n",
      "1000 train written\n",
      "1250 train written\n",
      "1500 train written\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "numpy_to_tfrecords(X_train, y_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_edge",
   "language": "python",
   "name": "dl_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
