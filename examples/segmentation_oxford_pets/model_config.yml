name: "model_a"
start_fresh: True

# TODO: it could be assumed that if only one layer in is defined in main, that
# it could be the `in_name` to the first layer.
layers:
  down_1:
    type: "down_block"
    source: "layer/block_module.py"
    options:
      filters: 16
      down_size: 2 # out: 64x64
      activation:
        type: elu
    in_name: "x_image"
  down_2:
    type: "down_block"
    source: "layer/block_module.py"
    options:
      filters: 32
      down_size: 2 # out: 32x32
      activation:
        type: elu
  down_3:
    type: "down_block"
    source: "layer/block_module.py"
    options:
      filters: 32
      down_size: 2 # out: 16x16
      activation:
        type: elu
  up_1:
    type: "up_block"
    source: "layer/block_module.py"
    options:
      filters: 32
      upsize: 2 # out: 32x32
      activation:
        type: elu
  concat_1:
    type: "concatenate"
    in_name: ["up_1", "down_2"]
  up_2:
    type: "up_block"
    source: "layer/block_module.py"
    options:
      filters: 32
      upsize: 2 # out: 64x64
      activation:
        type: elu
  concat_2:
    type: "concatenate"
    in_name: ["up_2", "down_1"]
  up_3:
    type: "up_block"
    source: "layer/block_module.py"
    options:
      filters: 32
      upsize: 2 # out: 128x128
      activation:
        type: elu
  concat_3:
    type: "concatenate"
    in_name: ["up_3", "x_image"]
  compress_1:
    type: "multipath"
    source: "layer/block_module.py"
    options:
      filters: 32
      padding: same
      activation:
        type: elu
  channel_compress:
    type: "conv2d"
    options:
      filters: 8
      padding: same
      kernel_size: 1
      strides: 1
      activation:
        type: elu
  y_pred:
    type: "conv2d"
    options:
      filters: 3
      padding: same
      kernel_size: 1
      strides: 1
      activation:
        type: linear
    endpoint: True
